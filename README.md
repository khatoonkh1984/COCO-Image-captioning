# COCO-Image-captioning
Coco-Image captioning


Image captioning is the process of generating a textual description of an image. It uses both natural language processing and computer vision to generate captions. The dataset will be in the form [image â†’ captions]. The dataset consists of input images and their corresponding output captions. The image captioning model consists of an encoder and a decoder. The encoder extracts significant features from the image. The decoder takes those features as inputs and uses them to generate the caption. The convolutional neural network (CNN) can be thought of as an encoder. The input image is given to CNN to extract the features. The last hidden state of the CNN is connected to the decoder. The decoder is a recurrent neural network (NN) that models language up to the word level.
